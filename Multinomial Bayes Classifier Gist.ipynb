{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''LIBRARY IMPORTS'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import seaborn as sb\n",
    "import re\n",
    "import os, types\n",
    "\n",
    "from datasets import list_datasets,load_dataset\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_score, recall_score, accuracy_score, balanced_accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140349b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DATA IMPORTS '''\n",
    "\n",
    "df = ### YOUR DATA HERE, IN A PANDAS DATAFRAME\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "In your dataframe, you must have a column with the text, a column with the text category, and then the respective code for the text category. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550923e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DATA CLEANING \"\"\"\n",
    "\n",
    "'''SOURCE CODE: ['https://github.com/ekavlako/think/blob/main/tutorials/naive-bayes/naive-bayes-tutorial.ipynb?utm_source=ibm_developer&utm_content=in_content_link&utm_id=tutorials_awb-classifying-data-multinomial-naive-bayes-algorithm]'''\n",
    "\n",
    "\n",
    "  ## This function takes a text, requests a parameter for stemming, and then if stopwords should be removed. It uses regex to strip out any text irregularities like dates or special characters and then passes the cleaned text into filtered tokwns.\n",
    "  ## The output for this function is a cleaned string of text.\n",
    "def text_clean(text, method, rm_stop):\n",
    "    text = re.sub(r\"\\n\",\"\",text)   #remove line breaks\n",
    "    text = text.lower() #convert to lowercase\n",
    "    text = re.sub(r\"\\d+\",\"\",text)   #remove digits and currencies\n",
    "    text = re.sub(r'[\\$\\d+\\d+\\$]', \"\", text)\n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)   #remove dates\n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)   #remove non-ascii\n",
    "    text = re.sub(r'[^\\w\\s]','',text)   #remove punctuation\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)   #remove hyperlinks\n",
    "\n",
    "    #remove stop words\n",
    "    if rm_stop == True:\n",
    "        filtered_tokens = [word for word in word_tokenize(text) if not word in set(stopwords.words('english'))]\n",
    "        text = \" \".join(filtered_tokens)\n",
    "\n",
    "    #lemmatization: typically preferred over stemming\n",
    "    if method == 'L':\n",
    "        lemmer = WordNetLemmatizer()\n",
    "        lemm_tokens = [lemmer.lemmatize(word) for word in word_tokenize(text)]\n",
    "        return \" \".join(lemm_tokens)\n",
    "\n",
    "    #stemming\n",
    "    if method == 'S':\n",
    "        porter = PorterStemmer()\n",
    "        stem_tokens = [porter.stem(word) for word in word_tokenize(text)]\n",
    "        return \" \".join(stem_tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157426db",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PRERPOCESSING USING LEMMAS '''\n",
    "\n",
    "  ## This section of code uses the above function to utilize PorterStemmer to create a bag of words utterance. This removes any potential inconsistencies in the data and makes it easier to convert during feature extraction.\n",
    "corpus = []\n",
    "for i in range (0,len(df)):\n",
    "    text = text_clean(df['Utterance'][i],\"S\",True)\n",
    "    corpus.append(text)\n",
    "\n",
    "  ## Let's create a column in the dataframe to append the corpus next to the utterances\n",
    "\n",
    "df.insert(1,'PS',corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DATASET SPLIT EDA '''\n",
    "ax = sb.countplot(x=df['COLUMN CLASSIFICATION NAME'])\n",
    "plt.title(\"Obersvations by Classification Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50412f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' FEATURE EXTRACTION '''\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "'''X is defined as the qualitative data and y is defined as the numerical label for the coded utterances.'''\n",
    "X = count_vectorizer.fit_transform(df['TEXT DATA'])\n",
    "y = df['NUMERICAL LABEL'] \n",
    "\n",
    "'''This cell assigns the variables of the list output of the train_test_split. These outputs will be used to put into the MNB.'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TRAINING THE MNB '''\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' EVALUATING PREFORMANCE '''\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print (f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CONFUSION MATRIX '''\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PREDICTIONS '''\n",
    "\n",
    "## First creating a list of new utterances. The list passed in will have one of each from the above dialogue acts\n",
    "new_utterance = ['I need you to finalize the reports by Monday',\n",
    "                 'The documentation can better explain it sometimes',\n",
    "                 'Plants function of phtosynthesis is crucial for sustaining life on Earth',\n",
    "                 'What are the strategies that you use to validate a models accuracy?'\n",
    "                 ]\n",
    "\n",
    "\n",
    "  ## Now lets tranform the new utterances using the same count_vectorizer as earlier\n",
    "new_X = count_vectorizer.transform(new_utterance)\n",
    "\n",
    "  ## Use model.predict() to identify the predicted labels for the text and print them out\n",
    "predicted_label = model.predict(new_X)\n",
    "print (predicted_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
