{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb8059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' LIBRARY IMPORT '''\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import regex as re\n",
    "import plotly.express as px\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0a2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DATASET IMPORT ''''\n",
    "\n",
    "data = pd.DataFrame(\" YOUR DATA HERE , READ FROM FILE PATH\")\n",
    "data_list = data[' TEXT COLUMN '].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DATASET CLEANING '''\n",
    "  ## To call and instantiate the stopwords:\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "  ## To call and instantiate the snowball stemmer ☃️\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english',ignore_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988125c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' WORD FREQUENCIES COUNTING '''\n",
    "\n",
    "\n",
    "## Instantiating our dictionary to count the words in\n",
    "word_counter = {}\n",
    "\n",
    "\n",
    "## Iterating through every tweet\n",
    "for tweet in data_list:\n",
    "\n",
    "  ## Identifying each word by splitting the tweet on blank or white spaces.\n",
    "  words = tweet.split(\" \")\n",
    "\n",
    "  ## Iterating through each word and filtering out actual alphabetical characters using Regex\n",
    "  for word in words:\n",
    "    matches = re.findall('\\D*',word)\n",
    "    word = matches[0]\n",
    "\n",
    "    ## Stemming the word using the porter stemmer\n",
    "    stem = stemmer.stem(word)\n",
    "\n",
    "    ## Counting the words\n",
    "    ## First, checking if the word has already been counted in the dictionary, and if not creating a new value for it\n",
    "    if len(stem) != 0:\n",
    "        if stem not in word_counter.keys():\n",
    "            word_counter[stem] = 1\n",
    "\n",
    "    else:\n",
    "        word_counter[stem] = word_counter[stem] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c55ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' EXAMINING THE CREATED DICTIONARY '''\n",
    "\n",
    "## First, let's see how many unique words are in the vocabulary\n",
    "\n",
    "unique_words = len(word_counter.keys())\n",
    "print (\"The number of the unique words in the vocabulary is:\",unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520684b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CREATING A FILTERED WORD COUNTER '''\n",
    "\n",
    "  ## Creating a storage dictionary for the words with the highest frequencies\n",
    "filtered_word_counter = {}\n",
    "\n",
    "## Iterating through every word and checking to see if there is over a certain amont of words\n",
    "for key in word_counter.keys():\n",
    "    if word_counter[key] > 10:  ## This can be changed based on any threshold. Setting this to 10 is an arbitrary decision.\n",
    "\n",
    "    ## Checking to see if the word is not a stopword\n",
    "        if key not in stopwords:\n",
    "\n",
    "          ## Checking to see if the word has signficance\n",
    "          if len(key) >2:\n",
    "            filtered_word_counter[key] = word_counter[key]\n",
    "            \n",
    "''' CREATING A FILTERED DATA FRAME'''\n",
    "## To know what parameters are avaiable this can be further explored on the pandas documentation\n",
    "## It requires some manipulation to ensure that the data is accurately represented.\n",
    "filtered_words = pd.DataFrame(filtered_word_counter,index=['value']).transpose().reset_index().sort_values(by='value',ascending=False)\n",
    "\n",
    "\n",
    "''' CREATING A COLUMN FOR PERCENTAGE '''\n",
    "\n",
    "## Creating a value for how many instances of the words were present in the corpus\n",
    "filtered_corpus_size = filtered_words['value'].agg('sum')\n",
    "\n",
    "## Let's look to see what percentage of the corpus each word composes of. To do so, we can use a lambda function.\n",
    "filtered_words['percentage'] = filtered_words['value'].apply(lambda x: x/filtered_corpus_size )\n",
    "\n",
    "## Storing the list of words, in greatest to least order\n",
    "words = filtered_words['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' READING SOME OF THE WORDS '''\n",
    "\n",
    "## We can look at the keys of the filtered word counter to see what the highest frequency words are.\n",
    "## The output of keys is in order they were added to the dictionary, not the highest frequency.\n",
    "filtered_word_counter.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fe24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Looking at the top ten words using Pandas head feature\n",
    "filtered_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1344b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DOWNLOADING THE VADER LEXICON AND SENTIMENT ANALYZER '''\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "''' ANALYZING FOR SENTIMENT '''\n",
    "\n",
    "## Creating a storage list for each end of the emotion scale\n",
    "neg = []\n",
    "neu = []\n",
    "pos = []\n",
    "compound = []\n",
    "\n",
    "## Iterating through the words to generate a sentiment score\n",
    "for word in words:\n",
    "    sentiment = sia.polarity_scores(word)\n",
    "    \n",
    "    ## Storing the current scores in the lists\n",
    "    curr_neg = sentiment['neg']\n",
    "    curr_neu = sentiment['neu']\n",
    "    curr_pos = sentiment['pos']\n",
    "    curr_compound = sentiment['compound']\n",
    "    \n",
    "    neg.append(curr_neg)\n",
    "    neu.append(curr_neu)\n",
    "    pos.append(curr_pos)\n",
    "    compound.append(curr_compound)\n",
    "    \n",
    "    \n",
    "''' EXPANDING THE DATAFRAME '''\n",
    "\n",
    "## Applying each of the lists to a new column in the dataframe\n",
    "filtered_words['neg'] = neg\n",
    "filtered_words['neu'] = neu\n",
    "filtered_words['pos'] = pos\n",
    "filtered_words['compound'] = compound\n",
    "\n",
    "\n",
    "''' SORTING THE DATAFRAME '''\n",
    "\n",
    "## Using the filtered_words dataframe to sort the values by compound, so the most positive words will occur first.\n",
    "compound_sorted = filtered_words.sort_values(by='compound',ascending=False)\n",
    "compound_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' AGGREGATING UPON SENTIMENT VALUES '''\n",
    "neg_sum = filtered_words['neg'].agg('sum')\n",
    "pos_sum = filtered_words['pos'].agg('sum')\n",
    "neu_sum = filtered_words['neu'].agg('sum')\n",
    "compound_sum = filtered_words['compound'].agg('sum')\n",
    "\n",
    "## Seeing what is the value of words that have a negative, neutral, or positive score. All words will have a compound score\n",
    "neg_query = filtered_words.query('neg != 0')\n",
    "neg_value = neg_query['value'].agg('sum')\n",
    "neg_perc = neg_value / filtered_corpus_size\n",
    "\n",
    "pos_query = filtered_words.query('pos != 0')\n",
    "pos_value = pos_query['value'].agg('sum')\n",
    "pos_perc = pos_value / filtered_corpus_size\n",
    "\n",
    "neu_query = filtered_words.query('neu != 0')\n",
    "neu_value = neu_query['value'].agg('sum')\n",
    "neu_perc = neu_value / filtered_corpus_size\n",
    "\n",
    "''' DATAFRAME CREATION '''\n",
    "calculations = {'neg freq':neg_value,'neg sia':neg_sum,'neg perc':neg_perc,\n",
    "                'neu freq':neu_value,'neu sia':neu_sum,'neu perc':neu_perc,\n",
    "                'pos freq':pos_value,'pos sia':pos_sum,'pos perc':pos_perc,}\n",
    "\n",
    "sentiment_calculations = pd.DataFrame.from_dict(calculations,orient='index')\n",
    "percentages = pd.DataFrame.from_dict({'neu perc':neu_perc,'pos perc':pos_perc,'neg perc':neg_perc},orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f490219",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' VISUALIZATION '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2517d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 1. WORD FREQUENCY DISTIRBUTION '''\n",
    "\n",
    "ax = sb.barplot(filtered_words,x='index',y='value')\n",
    "ax.set(title='Filtered Word Frequency Distribution')\n",
    "ax.set(xticklabels=[])\n",
    "ax.tick_params(bottom=False)\n",
    "ax;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce35a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 2. WHAT ARE THE MOST POSITVE WORDS? '''\n",
    "fig = px.bar(compound_sorted.query('compound != 0'),x='index', y=\"compound\",title = 'Highest Frequency COVID-19 Tweets: Compound Word Scores')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 3. WHAT IS THE PERCENTAGE OF EMOTION IN THE HIGHEST FREQUENCY WORDS? '''\n",
    "fig = px.funnel(percentages, x=0,y=['neu perc','pos perc','neg perc'],title='Highest Frequency COVID-19 Tweets: Percentage of Sentiment')\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
